---
layout: single
title:  "Yolov5 파인 튜닝 실습"
categories: 딥러닝
tag: [딥러닝, python, 객체탐지, Yolov5]
toc: true
toc_sticky: true

---

<head>
  <style>
    table.dataframe {
      white-space: normal;
      width: 100%;
      height: 240px;
      display: block;
      overflow: auto;
      font-family: Arial, sans-serif;
      font-size: 0.9rem;
      line-height: 20px;
      text-align: center;
      border: 0px !important;
    }

    table.dataframe th {
      text-align: center;
      font-weight: bold;
      padding: 8px;
    }

    table.dataframe td {
      text-align: center;
      padding: 8px;
    }

    table.dataframe tr:hover {
      background: #b8d1f3; 
    }

    .output_prompt {
      overflow: auto;
      font-size: 0.9rem;
      line-height: 1.45;
      border-radius: 0.3rem;
      -webkit-overflow-scrolling: touch;
      padding: 0.8rem;
      margin-top: 0;
      margin-bottom: 15px;
      font: 1rem Consolas, "Liberation Mono", Menlo, Courier, monospace;
      color: $code-text-color;
      border: solid 1px $border-color;
      border-radius: 0.3rem;
      word-break: normal;
      white-space: pre;
    }

  .dataframe tbody tr th:only-of-type {
      vertical-align: middle;
  }

  .dataframe tbody tr th {
      vertical-align: top;
  }

  .dataframe thead th {
      text-align: center !important;
      padding: 8px;
  }

  .page__content p {
      margin: 0 0 0px !important;
  }

  .page__content p > strong {
    font-size: 0.8rem !important;
  }

  </style>
</head>

# 객체 탐지용 오픈소스 Yolov5 사용

- 객체 영역 판단과 객체 인식을 동시에 진행하는 **One-stage detector** 방식
- 기존 CNN은 이미지 전체를 하나의 레이블(클래스)로 표시한다면, Yolo는 이미지 내에 특정한 위치(영역 추정)와 객체 탐지를 동시에 진행한 후, 이를 설정된 레이블로 표시해줌

## 1. 데이터 수집

- CNN처럼 이미지와 정답만 있으면 되는 것이 아니라 이미지 내에 정답이 될 객체들을 일일이 분리(라벨링)해서 정답으로 설정해줘야 함
- roboflow 사이트에서 이미 라벨링 된 권총 데이터 사용 https://roboflow.com/
- 실제 프로젝트에서 사용할 만한 라벨링 데이터는 ‘labelimg’ 라는 툴이 있음

```python
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
```

### 라벨링 된 권총 데이터 불러오기(from roboflow)

- 코드로 권총 데이터셋을 다운로드하면, export 폴더(images, labels 존재)와 README파일 2개, data.yaml 파일이 다운로드 된다.
- 위 파일들을 roboflow_dataset이라는 디렉토리를 생성 후 이동시켜 줌
- images
    - 실제 학습 이미지 데이터
    - labels의 첫번째 0은 권총이라는 label(class)를 의미
- labels
    - 객체에 대한 정보들이 표시되어 있음
    - 나머지 값들은 Bbox의 x, y, w, h 값을 의미

```python
! curl -L "https://public.roboflow.com/ds/0wHxiSXST0?key=CMDIufmI48" > roboflow.zip; unzip roboflow.zip; rm roboflow.zip
```

### 환경설정 및 사전작업

1. 소스코드 가져오기
- Yolov5 github url : https://github.com/ultralytics/yolov5
- 위의 url을 복사, github clone으로 yolov5 소스코드 복제해오기
- Google Drive의 /content 내에 yolov5 코드 복제함

```python
%cd /content

!git clone https://github.com/ultralytics/yolov5
```

1. yolov5 구동에 필요한 라이브러리 정의
- yolov5 폴더 내에 requirements.txt에 필요한 라이브러리 정보가 정의되어 있음
- 로컬 환경에서 작업하면 필요한 라이브러리 버전을 맞추는데에 어려움이 있어 Colab 환경에서 실행함

```python
# 해당 경로 파일의 모든 내용을 출력
%cd /content/yolov5/

!pip install -r requirements.txt
```

1. data.yaml 파일 내용 확인
- 데이터에 대한 정보가 담겨져 있는 파일로 yolo 학습시 사용
- data.yaml 파일 내용 출력해보기

```python
%cat /content/roboflow_dataset/data.yaml
```

```
train: ../train/images
val: ../valid/images

nc: 1
names: ['pistol']
```

1. 이미지 데이터 불러오기
- glob : 많은 양의 파일들의 처리를 쉽게 해주는 라이브러리
- glob처리하면 img_list 변수에는 이미지 데이터들의 경로값이 담기게 된다.

```python
from glob import glob

img_list = glob('/content/roboflow_dataset/export/images/*.jpg')
len(img_list)
```

```
2971
```

- Train/Val 데이터 분리

```python
from sklearn.model_selection import train_test_split

train_img_list, val_img_list = train_test_split(img_list, test_size=0.2, random_state=11)
len(train_img_list), len(val_img_list)
```

```
(2376, 595)
```

- 데이터 경로들을 하나의 txt파일에 담아주기(train, val 별도)

```python
# train
with open('/content/roboflow_dataset/train.txt', 'w') as f:
    f.write('\n'.join(train_img_list) + '\n')
# val
with open('/content/roboflow_dataset/val.txt', 'w') as f:
    f.write('\n'.join(val_img_list) + '\n')
```

1. data.yaml 파일의 train, val 경로를 맞게 재설정해주기
- data.yaml 파일 읽어오기

```python
import yaml
with open('/content/roboflow_dataset/data.yaml', 'r') as f:
    data = yaml.safe_load(f)data
```

```
{'train': '../train/images',
 'val': '../valid/images',
 'nc': 1,
 'names': ['pistol']}
```

- data.yaml은 key, value 쌍의 딕셔너리 형태로 load됨
- 경로 재설정하기

```python
data['train'] = '/content/roboflow_dataset/train.txt'
data['val'] = '/content/roboflow_dataset/val.txt'data
```

```
{'train': '/content/roboflow_dataset/train.txt',
 'val': '/content/roboflow_dataset/val.txt',
 'nc': 1,
 'names': ['pistol']}
```

- yaml.dump로 data.yaml파일에서 data의 값들을 f에 덮어씌우기

```python
with open('/content/roboflow_dataset/data.yaml', 'w') as f:
    yaml.dump(data, f)
```

### 모델 학습

- 모델을 학습시키는데 필요한 코드 파일인 train.py를 실행시킨다.

### train.py 옵션

- –img : 입력 이미지의 크기, 해당 이미지 데이터의 크기는 416 X 416이다.
- –batch : 배치 사이즈 설정(데이터의 양이 많기 때문에 메모리를 고려하여 16정도까지만 높여줌)
- –data : data.yaml 파일 경로 설정
- –cfg : yolo 모델의 세부 모델 설정(s, m, l, x 등)
- –weights : 기존 모델에 학습되어 있는 가중치 값을 그대로 사용(사용하는 모델의 가중치를 기입해야함, yolov5s.pt), 일부는 사용 목적에 맞게 재학습되도록 설정되어 있음
- –name : 저장되는 결과 파일명

```python
%cd /content/yolov5

!python train.py --img 416 --batch 16 --epochs 50 --data /content/roboflow_dataset/data.yaml --cfg ./models/yolov5s.yaml --weights yolov5s.pt --name gun_yolov5s_results
```

### yolov5모델 학습 결과 해석


![result1.png](/assets/images/DL06/result1.png)

<br>

![09_3.png](/assets/images/DL06/09_3.png)

### 1. mAP50

- IoU = 0.5(실제와 예측이 50% 이상 겹쳤을 때 정답이라고 본다)일 때의 점수

### 2. mAP50-95

- IoU값을 0.5에서 0.05씩 증가시키며 0.95까지의 mAP값들의 평균값

보통 mAP50으로 모델의 성능을 판단하지만, 더 복잡해질 상황을 고려한다면 mAP50-95와 같이 판단, 고려해야함

## 학습 완료 후 평가지표

- 학습이 완료되면 모델 학습 설정에서 지정한 결과 파일명에 해당하는 디렉토리가 생성된다.
- 해당 폴더의 ./weights의 best.pt, last.pt
    - best.pt : 학습 진행 중 가장 mAP가 높았을 때의 가중치가 저장됨
    - last.pt : 마지막 epoch에서의 가중치가 저장됨

### 평가지표 시각화하기

- 평가지표들을 tensorboard로 시각화해서 결과를 보기 쉽게 출력해보기

```python
%load_ext tensorboard
%tensorboard --logdir /content/yolov5/runs
```
![09_4.jpg](/assets/images/DL06/result2.png)


## 모델 테스트

- 실제로 이미지를 넣어 제대로 검출되는지 확인해보기
- 학습에 사용되지 않은 val 데이터로 확인

### 1. 검증용 데이터에서 임의로 한장 불러오기

```python
from IPython.display import Image

val_img_path = val_img_list[8]
Image(val_img_path)
```

![09_4.jpg](/assets/images/DL06/09_4.jpg)

### 2. 학습된 yolo 모델에 객체 검출 요청하기

- detect.py 파일을 실행하여 모델에 요청한다
- –weights 가중치 설정, 여기서는 best.pt(mAP가 가장 좋은 가중치)로 설정하였다.
- –conf : 0.5로 설정하였으므로 점수가 0.5보다 낮은 결과가 나오면 출력이 되지 않는다.

```python
!python detect.py --weights /content/yolov5/runs/train/gun_yolov5s_results/weights/best.pt --img 416 --conf 0.5 --source "{val_img_path}"
```

![result3.png](/assets/images/DL06/result3.png)

- 결과 확인은 runs/detect/exp로 저장되었다고 나와있음
- 여러번 하면 exp2, exp3, … 로 저장되게 된다.
- 결과 형태를 변경하고 싶거나, 다른 처리를 위해 핸들링하기 위해선 detect.py 파일 내의 코드를 수정하면 된다.


![09_5.png](/assets/images/DL06/09_5.png)